{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R17_gCYEpUj6"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDnpx1sopUj9"
      },
      "source": [
        "## Preparación del entorno.\n",
        "\n",
        "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkzRyzPrpUj-",
        "outputId": "0f011fd1-4e99-4062-9a8f-9d80f864aa23"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_NAME = \"lab7\"\n",
        "if REPO_NAME not in os.getcwd():\n",
        "  if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
        "  os.chdir(REPO_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWRXk_wfpUj-"
      },
      "source": [
        "Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-0gu4nNpUj_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, GlobalMaxPooling2D\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJT506AXpUj_"
      },
      "source": [
        "Establecer GPU por defecto en caso de estar disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMPBKDUqpUkA",
        "outputId": "628c8777-41dd-42c8-aee2-b981574d53f9"
      },
      "outputs": [],
      "source": [
        "# Configurar para que TensorFlow utilice la GPU por defecto\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        # Especificar la GPU por defecto\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Manejar error\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFivZvwrr3c"
      },
      "source": [
        "Cargar dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4SEGiicron5",
        "outputId": "5536eb9b-2680-4b70-af81-a3d12224fa64"
      },
      "outputs": [],
      "source": [
        "# Directorio de los datos\n",
        "TRAIN_DATA_DIRECTORY = Path(\"dataset/train\")\n",
        "VALIDATION_DATA_DIRECTORY = Path(\"dataset/validation\")\n",
        "\n",
        "# Tamaño del lote (batch size)\n",
        "BATCH_SIZE = 32\n",
        "# Tamaño de las imágenes\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_WIDTH = 224\n",
        "\n",
        "# Carga los datos de entrenamiento y validación\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DATA_DIRECTORY,\n",
        "    label_mode=\"categorical\",\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    VALIDATION_DATA_DIRECTORY,\n",
        "    label_mode=\"categorical\",\n",
        "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "    batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t2GvwFlsDxB"
      },
      "source": [
        "Inspeccionar las clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYKVTIssDxC",
        "outputId": "8ab86baa-f409-456b-8524-5b747c7a9e1c"
      },
      "outputs": [],
      "source": [
        "# Obtiene los nombres de las clases\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reducimos el tamaño del dataset para emular un escenario real donde no tenemos muchos datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = train_ds.take(200)\n",
        "val_ds = val_ds.take(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubJrSBs93n_w"
      },
      "source": [
        "Visualizar los datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "6qEllzoh3n_y",
        "outputId": "76625eb0-e3d3-4fd4-b373-a9d015b0d00a"
      },
      "outputs": [],
      "source": [
        "# Muestra algunas imágenes de ejemplo\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    class_idx = list(labels[i]).index(1)\n",
        "    plt.title(class_names[class_idx])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPc6bR40slUd"
      },
      "source": [
        "Definir la arquitectura de la red:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP7JcxqnslUk"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape, num_classes):\n",
        "    base_model = tf.keras.applications.EfficientNetB0(input_shape=input_shape,\n",
        "                                                include_top=False,\n",
        "                                                weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    i = Input(shape=input_shape)\n",
        "    x = base_model(i, training=False)\n",
        "    x = GlobalMaxPooling2D()(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return tf.keras.Model(i, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqmagBPQtR4P"
      },
      "source": [
        "Construir el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwjh6aoatR4W",
        "outputId": "4f00bcfc-8689-4894-cb71-9779a5336a0c"
      },
      "outputs": [],
      "source": [
        "print(\"Building model\")\n",
        "model = build_model((IMAGE_HEIGHT, IMAGE_WIDTH, 3), num_classes)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtd0tlWitelD"
      },
      "source": [
        "Resumen del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MiIn1u5telJ",
        "outputId": "934f8b1b-152b-49dc-bd82-162ad293c8e3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18XCTIAq2xvu"
      },
      "source": [
        "Entrenar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CPqN1z72xv0",
        "outputId": "26659a03-851e-4037-9223-0dd11382f709"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\")\n",
        "checkpoint_acc = ModelCheckpoint(\n",
        "    \"model-e{epoch:02d}-loss{val_loss:.3f}-acc{val_accuracy:.3f}\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    initial_value_threshold=0.7,\n",
        "    mode=\"max\",\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"loss\", factor=0.5, patience=20, verbose=1, epsilon=1e-4, mode=\"min\"\n",
        ")\n",
        "\n",
        "# Número de épocas de entrenamiento\n",
        "EPOCHS = 50\n",
        "# Entrena el modelo\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint_acc, reduce_lr, early_stopping],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-V-eXRc3CiA"
      },
      "source": [
        "Visualizar resultados de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "qAArNY393CiG",
        "outputId": "25dad8d3-27e1-439c-f112-95083e283421"
      },
      "outputs": [],
      "source": [
        "# Grafica la precisión y pérdida de entrenamiento y validación\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmo de clasificacion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_img(img):\n",
        "    img_pred = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)  # Convert head crop to RGB format\n",
        "    img_pred = cv2.resize(img_pred, (IMAGE_WIDTH, IMAGE_WIDTH))  # Resize the image\n",
        "    img_pred = np.expand_dims(img_pred, axis=0)  # Expand dimensions to create batch\n",
        "    predictions = model(img_pred)  # Perform hat classification\n",
        "    predicted_score = np.max(predictions) # Get the max score\n",
        "    predicted_class_index = np.argmax(predictions)  # Get index of predicted class\n",
        "    predicted_class = class_names[predicted_class_index]  # Get predicted class\n",
        "    return predicted_class, predicted_score # Return predicted hat class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmo de ventana deslizante con tamaño fijo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sliding_window(image, step_size, window_size):\n",
        "    \"\"\"\n",
        "    Genera regiones de una imagen utilizando el algoritmo de ventana deslizante.\n",
        "\n",
        "    Args:\n",
        "        image: Imagen de entrada.\n",
        "        step_size: Tamaño del paso para desplazar la ventana.\n",
        "        window_size: Tamaño de la ventana (altura, ancho).\n",
        "\n",
        "    Returns:\n",
        "        Una lista de tuplas (x, y, ventana) donde (x, y) es la esquina superior izquierda\n",
        "        de la ventana y ventana es la región de la imagen cubierta por la ventana.\n",
        "    \"\"\"\n",
        "    windows = list()\n",
        "    # Itera sobre las coordenadas (x, y) de la imagen con el paso especificado\n",
        "    for y in range(0, image.shape[0] - window_size[0] + 1, step_size):\n",
        "        for x in range(0, image.shape[1] - window_size[1] + 1, step_size):\n",
        "            # Define la región de la imagen cubierta por la ventana\n",
        "            crop = image[y:y+window_size[0], x:x+window_size[1]]\n",
        "            # Aplica el modelo de clasificacion\n",
        "            predicted_class, predicted_score = classify_img(crop)\n",
        "            # Crea la tupla window = (x, y, w, h, class, score)\n",
        "            window = (x, y, window_size[1], window_size[0], predicted_class, predicted_score)\n",
        "            windows.append(window)\n",
        "    return windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmo de ventana deslizante con tamaño variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sliding_window_variable(image):\n",
        "    \"\"\"\n",
        "    Genera todas las regiones posibles de una imagen utilizando iteradamente el algoritmo de ventana deslizante.\n",
        "\n",
        "    Args:\n",
        "        image: Imagen de entrada.\n",
        "\n",
        "    Returns:\n",
        "        Una lista de tuplas (x, y, w, h, class, score) donde (x, y) es la esquina superior izquierda\n",
        "        de la ventana, w y h son el ancho y alto de la ventana, respectivamente, y class y score son\n",
        "        la clase predicha y la puntuación correspondiente para esa ventana.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmo NMS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def nms(windows, threshold):\n",
        "    \"\"\"\n",
        "    Aplica el algoritmo de supresión de no máximos (NMS) a las ventanas.\n",
        "\n",
        "    Args:\n",
        "        windows: Lista de tuplas que representan las ventanas, cada tupla en el formato (x, y, w, h, class, score).\n",
        "        threshold: Umbral de solapamiento para decidir si dos ventanas deben suprimirse.\n",
        "\n",
        "    Returns:\n",
        "        Una lista de ventanas después de aplicar NMS.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmo para dibujar detecciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_bboxes(filtered_windows, image):\n",
        "    \"\"\"\n",
        "    Dibuja los bounding boxes de las ventanas filtradas con su clase sobre la imagen.\n",
        "\n",
        "    Args:\n",
        "        filtered_windows: Lista de tuplas que representan las ventanas, cada tupla en el formato (x, y, w, h, class, score).\n",
        "\n",
        "    Returns:\n",
        "        Una imagen con los bouding boxes y sus respectivas clases.\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementacion final:\n",
        " - Comparar resultados de sliding window con tamaño fijo para distintos valores de step_size y window_size.\n",
        " - Comparar resultados de sliding window con tamaño fijo y variable.\n",
        " - Aplicar NMS sobre los resultados del sliding window con tamaño variable.\n",
        "\n",
        "En todos los casos aplicar un treshold de score sobre las windows y dibujar las detecciones sobre las imagenes.\n",
        "Utilizar como imagenes de entrada las que se encuentran en la carpeta ./detection-test-images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
